"""
åšå®¢è´¨é‡è¯„ä¼°æ¨¡å—
ä½¿ç”¨ Claude Code CLI è¯„ä¼°ç”Ÿæˆçš„åšå®¢è´¨é‡
"""

import subprocess
import json
import re
from pathlib import Path
from typing import Dict, Optional


class BlogEvaluator:
    """åšå®¢è´¨é‡è¯„ä¼°å™¨ - ä½¿ç”¨ Claude Code CLI"""

    def __init__(self, config: Dict = None):
        self.config = config or {}
        
        # æ£€æŸ¥ claude CLI æ˜¯å¦å¯ç”¨
        try:
            result = subprocess.run(
                ['claude', '--version'],
                capture_output=True,
                text=True,
                timeout=10
            )
            if result.returncode != 0:
                raise RuntimeError("Claude CLI è¿”å›é”™è¯¯")
        except FileNotFoundError:
            raise RuntimeError("æœªæ‰¾åˆ° Claude CLI")

    def evaluate_blog(self, blog_content: str, source_paper: Dict) -> Dict:
        """
        è¯„ä¼°åšå®¢è´¨é‡
        
        è¿”å›:
        {
            'overall_score': 1-10,
            'content_depth': {
                'score': 1-10,
                'comments': str
            },
            'code_quality': {
                'score': 1-10,
                'issues': [str],
                'runnable': bool
            },
            'structure': {
                'text_ratio': float,  # æ–‡å­—å æ¯”
                'code_ratio': float,  # ä»£ç å æ¯”
                'balanced': bool,
                'comments': str
            },
            'summary': str,
            'suggestions': [str]
        }
        """
        print("\nğŸ” æ­£åœ¨è¯„ä¼°åšå®¢è´¨é‡...")

        # è®¡ç®—æ–‡å­—/ä»£ç æ¯”ä¾‹
        text_code_ratio = self._calculate_ratio(blog_content)
        
        # æ„å»ºè¯„ä¼°æç¤ºè¯
        evaluation_prompt = self._build_evaluation_prompt(
            blog_content, 
            source_paper,
            text_code_ratio
        )

        # è°ƒç”¨ Claude CLI è¿›è¡Œè¯„ä¼°
        try:
            result = subprocess.run(
                [
                    'claude',
                    '-p',
                    '--model', 'sonnet',
                    '--tools', '',
                    '--dangerously-skip-permissions',
                ],
                input=evaluation_prompt,
                capture_output=True,
                text=True,
                timeout=180,  # 3åˆ†é’Ÿè¶…æ—¶
            )

            if result.returncode != 0:
                print(f"  âš ï¸ è¯„ä¼°å¤±è´¥: {result.stderr}")
                return self._default_evaluation(text_code_ratio)

            response = result.stdout.strip()
            evaluation = self._parse_evaluation(response, text_code_ratio)
            
            print(f"  âœ“ è¯„ä¼°å®Œæˆ")
            return evaluation

        except subprocess.TimeoutExpired:
            print("  âš ï¸ è¯„ä¼°è¶…æ—¶")
            return self._default_evaluation(text_code_ratio)
        except Exception as e:
            print(f"  âš ï¸ è¯„ä¼°é”™è¯¯: {e}")
            return self._default_evaluation(text_code_ratio)

    def _calculate_ratio(self, content: str) -> Dict:
        """è®¡ç®—æ–‡å­—å’Œä»£ç çš„æ¯”ä¾‹"""
        lines = content.split('\n')
        
        in_code_block = False
        code_lines = 0
        text_lines = 0
        code_chars = 0
        text_chars = 0
        
        # è·³è¿‡ front matter
        content_start = 0
        if lines[0].strip() == '---':
            for i, line in enumerate(lines[1:], 1):
                if line.strip() == '---':
                    content_start = i + 1
                    break
        
        for line in lines[content_start:]:
            if line.strip().startswith('```'):
                in_code_block = not in_code_block
                continue
            
            if in_code_block:
                code_lines += 1
                code_chars += len(line)
            else:
                # è·³è¿‡ç©ºè¡Œ
                if line.strip():
                    text_lines += 1
                    text_chars += len(line)
        
        total_chars = text_chars + code_chars
        if total_chars == 0:
            return {'text_ratio': 0.5, 'code_ratio': 0.5}
        
        text_ratio = text_chars / total_chars
        code_ratio = code_chars / total_chars
        
        return {
            'text_ratio': round(text_ratio, 2),
            'code_ratio': round(code_ratio, 2),
            'text_lines': text_lines,
            'code_lines': code_lines
        }

    def _build_evaluation_prompt(self, blog_content: str, source_paper: Dict, ratio: Dict) -> str:
        """æ„å»ºè¯„ä¼°æç¤ºè¯"""
        return f"""ä½ æ˜¯ä¸€ä½æŠ€æœ¯åšå®¢è´¨é‡è¯„ä¼°ä¸“å®¶ã€‚è¯·è¯„ä¼°ä»¥ä¸‹åšå®¢æ–‡ç« çš„è´¨é‡ã€‚

## åŸå§‹è®ºæ–‡ä¿¡æ¯
- æ ‡é¢˜: {source_paper.get('title', 'Unknown')}
- é“¾æ¥: {source_paper.get('url', 'Unknown')}
- æ‘˜è¦: {source_paper.get('summary', source_paper.get('description', 'N/A'))}

## å½“å‰æ–‡å­—/ä»£ç æ¯”ä¾‹
- æ–‡å­—å æ¯”: {ratio['text_ratio']:.0%}
- ä»£ç å æ¯”: {ratio['code_ratio']:.0%}
- ç†æƒ³æ¯”ä¾‹: æ–‡å­— 40-50%ï¼Œä»£ç  50-60%

## åšå®¢å†…å®¹
{blog_content[:15000]}  
{"[å†…å®¹å·²æˆªæ–­...]" if len(blog_content) > 15000 else ""}

---

è¯·ä»ä»¥ä¸‹ç»´åº¦è¯„ä¼°è¿™ç¯‡åšå®¢ï¼Œå¹¶ç»™å‡º 1-10 çš„è¯„åˆ†ï¼ˆ10åˆ†æœ€é«˜ï¼‰ï¼š

### 1. å†…å®¹æ·±åº¦ (content_depth_score)
- æ˜¯å¦å¯¹è®ºæ–‡æœ‰æ·±å…¥ç†è§£ï¼Ÿ
- æ˜¯å¦æœ‰æ´è§çš„è¯„è®ºå’Œæ€»ç»“ï¼Ÿ
- ä¸ä»…ä»…æ˜¯ç¿»è¯‘æˆ–ç®€å•å¤è¿°

### 2. ä»£ç è´¨é‡ (code_quality_score)  
- ä»£ç æ˜¯å¦å®Œæ•´ã€å¯è¿è¡Œï¼Ÿ
- æœ‰æ— è¯­æ³•é”™è¯¯æˆ–é€»è¾‘é—®é¢˜ï¼Ÿ
- æ³¨é‡Šæ˜¯å¦æ¸…æ™°ï¼Ÿ

### 3. ç»“æ„å¹³è¡¡ (structure_score)
- æ–‡å­—å’Œä»£ç æ¯”ä¾‹æ˜¯å¦åˆç†ï¼Ÿï¼ˆç†æƒ³ 4:6 æˆ– 5:5ï¼‰
- æ˜¯å¦æœ‰è¶³å¤Ÿçš„è§£é‡Šï¼Œè€Œéå †ç Œä»£ç ï¼Ÿ
- æ•´ä½“ç»“æ„æ˜¯å¦æ¸…æ™°ï¼Ÿ

### 4. æ€»ä½“è¯„åˆ† (overall_score)
- ç»¼åˆä»¥ä¸Šå„é¡¹ï¼Œç»™å‡º 1-10 çš„æ€»åˆ†

è¯·ç”¨ä»¥ä¸‹ JSON æ ¼å¼å›å¤ï¼ˆåªè¾“å‡º JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ï¼‰ï¼š

```json
{{
    "overall_score": <1-10>,
    "content_depth": {{
        "score": <1-10>,
        "comments": "<å¯¹å†…å®¹æ·±åº¦çš„è¯„ä»·>"
    }},
    "code_quality": {{
        "score": <1-10>,
        "runnable": <true/false>,
        "issues": ["<é—®é¢˜1>", "<é—®é¢˜2>"]
    }},
    "structure": {{
        "score": <1-10>,
        "balanced": <true/false>,
        "comments": "<å¯¹ç»“æ„çš„è¯„ä»·>"
    }},
    "summary": "<ä¸€å¥è¯æ€»ç»“>",
    "suggestions": ["<æ”¹è¿›å»ºè®®1>", "<æ”¹è¿›å»ºè®®2>"]
}}
```
"""

    def _parse_evaluation(self, response: str, ratio: Dict) -> Dict:
        """è§£æè¯„ä¼°ç»“æœ"""
        # å°è¯•æå– JSON
        json_match = re.search(r'```json\s*(.*?)\s*```', response, re.DOTALL)
        if json_match:
            try:
                result = json.loads(json_match.group(1))
                # æ·»åŠ æ¯”ä¾‹ä¿¡æ¯
                result['structure']['text_ratio'] = ratio['text_ratio']
                result['structure']['code_ratio'] = ratio['code_ratio']
                return result
            except json.JSONDecodeError:
                pass
        
        # å°è¯•ç›´æ¥è§£æ
        try:
            # æ‰¾åˆ°ç¬¬ä¸€ä¸ª { å’Œæœ€åä¸€ä¸ª }
            start = response.find('{')
            end = response.rfind('}') + 1
            if start >= 0 and end > start:
                result = json.loads(response[start:end])
                result['structure']['text_ratio'] = ratio['text_ratio']
                result['structure']['code_ratio'] = ratio['code_ratio']
                return result
        except json.JSONDecodeError:
            pass
        
        # è§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼
        print("  âš ï¸ æ— æ³•è§£æè¯„ä¼°ç»“æœï¼Œä½¿ç”¨é»˜è®¤å€¼")
        return self._default_evaluation(ratio)

    def _default_evaluation(self, ratio: Dict) -> Dict:
        """è¿”å›é»˜è®¤è¯„ä¼°ç»“æœ"""
        balanced = 0.35 <= ratio['text_ratio'] <= 0.55
        return {
            'overall_score': 7,
            'content_depth': {
                'score': 7,
                'comments': 'æ— æ³•è‡ªåŠ¨è¯„ä¼°ï¼Œè¯·äººå·¥å®¡é˜…'
            },
            'code_quality': {
                'score': 7,
                'runnable': True,
                'issues': []
            },
            'structure': {
                'score': 7 if balanced else 5,
                'text_ratio': ratio['text_ratio'],
                'code_ratio': ratio['code_ratio'],
                'balanced': balanced,
                'comments': 'æ–‡å­—/ä»£ç æ¯”ä¾‹' + ('åˆç†' if balanced else 'éœ€è¦è°ƒæ•´')
            },
            'summary': 'è‡ªåŠ¨è¯„ä¼°æœªèƒ½å®Œæˆï¼Œè¯·äººå·¥å®¡é˜…',
            'suggestions': ['è¯·äººå·¥å®¡é˜…å†…å®¹æ·±åº¦', 'è¯·æ£€æŸ¥ä»£ç å¯è¿è¡Œæ€§']
        }

    def format_evaluation_report(self, evaluation: Dict) -> str:
        """æ ¼å¼åŒ–è¯„ä¼°æŠ¥å‘Šï¼ˆç”¨äºé‚®ä»¶ï¼‰"""
        report = []
        report.append("=" * 50)
        report.append("ğŸ“Š AI è´¨é‡è¯„ä¼°æŠ¥å‘Š")
        report.append("=" * 50)
        report.append("")
        
        # æ€»åˆ†
        overall = evaluation.get('overall_score', 7)
        stars = 'â­' * min(overall, 10)
        report.append(f"ğŸ¯ æ€»ä½“è¯„åˆ†: {overall}/10 {stars}")
        report.append("")
        
        # å†…å®¹æ·±åº¦
        depth = evaluation.get('content_depth', {})
        report.append(f"ğŸ“š å†…å®¹æ·±åº¦: {depth.get('score', 7)}/10")
        report.append(f"   {depth.get('comments', 'N/A')}")
        report.append("")
        
        # ä»£ç è´¨é‡
        code = evaluation.get('code_quality', {})
        report.append(f"ğŸ’» ä»£ç è´¨é‡: {code.get('score', 7)}/10")
        report.append(f"   å¯è¿è¡Œ: {'âœ“ æ˜¯' if code.get('runnable', True) else 'âœ— å¦'}")
        if code.get('issues'):
            report.append("   é—®é¢˜:")
            for issue in code['issues'][:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ª
                report.append(f"   - {issue}")
        report.append("")
        
        # ç»“æ„å¹³è¡¡
        struct = evaluation.get('structure', {})
        report.append(f"ğŸ“ ç»“æ„å¹³è¡¡: {struct.get('score', 7)}/10")
        report.append(f"   æ–‡å­—å æ¯”: {struct.get('text_ratio', 0.5):.0%}")
        report.append(f"   ä»£ç å æ¯”: {struct.get('code_ratio', 0.5):.0%}")
        report.append(f"   æ¯”ä¾‹åˆç†: {'âœ“ æ˜¯' if struct.get('balanced', True) else 'âœ— éœ€è°ƒæ•´'}")
        report.append(f"   {struct.get('comments', '')}")
        report.append("")
        
        # æ€»ç»“
        report.append(f"ğŸ“ æ€»ç»“: {evaluation.get('summary', 'N/A')}")
        report.append("")
        
        # æ”¹è¿›å»ºè®®
        suggestions = evaluation.get('suggestions', [])
        if suggestions:
            report.append("ğŸ’¡ æ”¹è¿›å»ºè®®:")
            for s in suggestions[:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ª
                report.append(f"   - {s}")
        
        report.append("")
        report.append("=" * 50)
        
        return '\n'.join(report)


if __name__ == "__main__":
    # æµ‹è¯•
    evaluator = BlogEvaluator()
    
    test_content = """---
layout: post
title: "Test Blog"
---

# Introduction

This is a test blog about machine learning.

## Code Example

```python
import numpy as np

def train_model(X, y):
    # Training logic here
    return model
```

## Conclusion

This was a brief overview.
"""
    
    test_paper = {
        'title': 'Test Paper',
        'url': 'https://arxiv.org/abs/1234.5678',
        'summary': 'A paper about ML'
    }
    
    result = evaluator.evaluate_blog(test_content, test_paper)
    print(evaluator.format_evaluation_report(result))
